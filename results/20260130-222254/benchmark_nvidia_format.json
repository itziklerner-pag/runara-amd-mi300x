{
  "metadata": {
    "timestamp": "2026-01-31T06:02:29.920777Z",
    "model": "Llama v3.3 70B",
    "gpu": "1x MI300X",
    "server": "DO Gradient",
    "precision": "FP8",
    "framework": "vLLM 0.9.2",
    "gpu_memory_gb": 192
  },
  "benchmarks": [
    {
      "input_length": 128,
      "output_length": 2048,
      "throughput_tokens_per_sec": 33.1,
      "pp": 1,
      "tp": 1
    },
    {
      "input_length": 128,
      "output_length": 4096,
      "throughput_tokens_per_sec": 33.2,
      "pp": 1,
      "tp": 1
    },
    {
      "input_length": 2048,
      "output_length": 128,
      "throughput_tokens_per_sec": 32.4,
      "pp": 1,
      "tp": 1
    },
    {
      "input_length": 5000,
      "output_length": 500,
      "throughput_tokens_per_sec": 32.6,
      "pp": 1,
      "tp": 1
    },
    {
      "input_length": 500,
      "output_length": 2000,
      "throughput_tokens_per_sec": 33.1,
      "pp": 1,
      "tp": 1
    },
    {
      "input_length": 1000,
      "output_length": 1000,
      "throughput_tokens_per_sec": 33.2,
      "pp": 1,
      "tp": 1
    },
    {
      "input_length": 1000,
      "output_length": 2000,
      "throughput_tokens_per_sec": 33.1,
      "pp": 1,
      "tp": 1
    },
    {
      "input_length": 2048,
      "output_length": 2048,
      "throughput_tokens_per_sec": 33.0,
      "pp": 1,
      "tp": 1
    },
    {
      "input_length": 20000,
      "output_length": 2000,
      "throughput_tokens_per_sec": 0,
      "pp": 1,
      "tp": 1
    }
  ]
}